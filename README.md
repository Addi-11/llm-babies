# Quick Projects: Explaining Concepts of LLMs and Machine Learning Algorithms through Pet Projects

## Basic Projects

1. **[LLM Chat App Interface:](./llm-chat-app/)**
   - **Description:** Simple chatbot interface using openai endpoints

2. **[Movie Recommender Web-Application:](./movie-recommender-webapp/)**
   - **Description:** A simple recommender system using cosine similarity on movie tags to give suggestions.

## Tokenization and Pre-training

3. **[Hindi Lanugage Tokenization:](./tokenizer/)**
   - **Description:** Visualizing the process as well. Custom tokenizer for Hindi language using BPE.
   ![](./images/hindi_tokenizer.mp4)
   - **Reference:** [Tik-token visualizer](https://github.com/dqbd/tiktokenizer)

4. **Pre-training TinyLlama model:**
   - **Description:** Simulate a mini pre-training process using a small dataset and an LLM architecture.

5. **Instruction Tuning [TBD]:**

5. **Mid-training Techniques [TBD]:**
   - **Description:** Experiment with mid-training by fine-tuning a pre-trained model on a specialized dataset.

## Reinforcement Learning and Optimization

6. **Reinforcement Learning with Human Feedback (RLHF):**
   - **Description:** Implement a simple RLHF setup where users provide feedback on model outputs to improve performance.

7. **Proximal Policy Optimization (PPO):**
   - **Description:** Create a small reinforcement learning environment and apply PPO to train an agent.

8. **Direct Policy Optimization (DPO) [TBD]:**
   - **Description:** Develop a project showcasing the DPO algorithm in a natural language processing context.
   
## Model Optimization and Inference

9. **Quantization:**
   - **Description:** Implement model quantization to reduce the size of a pre-trained LLM and evaluate its performance.
   - **Evaluation:** Performance on inference benchmarks.
   
10. **Key-Value Caching (KVCache) [TBD]:**
    - **Description:** Develop a caching mechanism to optimize the performance of an LLM during inference.
    
11. **Fast Transformer Inference with Better Transformers:**
    - **Description:** Implement fast transformer inference following PyTorch tutorials.
    - **Visualization:** Use PyTorch Profiler to visualize or plot the inference performance.
    - **Reference:** [Better Transformers Tutorial](https://pytorch.org/tutorials/beginner/bettertransformer_tutorial.html), [PyTorch Profiler](https://pytorch.org/tutorials/beginner/profiler.html)

## Machine Learning Algorithms

12. **K-Means Clustering:**
    - **Description:** Implement k-means clustering to group similar text documents.

13. **Support Vector Machine (SVM):**
    - **Description:** Build an SVM classifier to categorize text into predefined categories.

## Advanced Projects

13. **LLM Agents / OpenAI Assistants[TBD]:** 
    - **Description:** 

14. **Text Generation and Creative Writing [TBD]:**
    - **Description:** Create a short story generator that uses prompts to generate creative narratives.

15. **Code Generation:**
    - **Description:** Develop a code snippet generator that creates basic code structures based on natural language descriptions.

## Multimodal and Distributed Training

16. **Multimodal Finetuning FLAVA:**
    - **Description:** Fine-tune a multimodal model following the PyTorch FLAVA tutorial.
    - **Reference:** [FLAVA Finetuning Tutorial](https://pytorch.org/tutorials/beginner/flava_finetuning_tutorial.html)

17. **Distributed Training:**
    - **Description:** Learn and implement distributed training techniques.
        - Distributed Applications with PyTorch
        - Advanced Model Training with Fully Sharded Data Parallel (FSDP)
        - Large Scale Transformer model training with Tensor Parallel (TP)
        - Distributed Pipeline Parallelism
        - Parameter Server Using Distributed RPC Framework
    - **Reference:** [PyTorch Distributed Training](https://pytorch.org/tutorials/distributed/home.html)

### Notes
- **TBD Projects:** These projects are marked as "TBD" (To Be Determined) and require further definition and planning.
